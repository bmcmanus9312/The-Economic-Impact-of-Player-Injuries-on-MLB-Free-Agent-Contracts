{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "# Inputs\n",
    "CONTRACTS_CSV = r\"mlb_free_agent_contracts_master_v1_3_with_player_keys.csv\"\n",
    "INJURIES_CSV  = r\"injuries_cleaned_v1_6_use.csv\"\n",
    "TERM_MAP_PATH = r\"injury_term_map_v1.txt\"\n",
    "\n",
    "# Outputs\n",
    "OUT_CONTRACTS   = r\"contracts_with_isi.csv\"\n",
    "OUT_AUDIT_TABLE = r\"injury_term_to_bucket_weights.csv\"\n",
    "OUT_COVERAGE    = r\"isi_mapping_coverage_report.csv\"\n",
    "\n",
    "# ISI settings\n",
    "LOOKBACK_YEARS = 3\n",
    "RECENCY_LAMBDA = 0.70\n",
    "DENOM_MODE = \"calendar\"     # \"calendar\" (365*years) or \"games\" (162*years)\n",
    "DAYS_CAP = 800\n",
    "INJURY_TO_CONTRACT_OFFSET = 0.50\n",
    "\n",
    "# Positional Parsing for Pitcher Specific Positions\n",
    "PITCHER_CODES = {\"P\", \"SP\", \"RP\", \"RHP\", \"LHP\"}\n",
    "\n",
    "SEVERITY_TIER_MULT = {\n",
    "    0: 1.00,\n",
    "    1: 1.00,\n",
    "    2: 1.15,\n",
    "    3: 1.30,\n",
    "}\n",
    "SURGERY_BONUS_MULT = 1.10       # if surgery_flag = 1\n",
    "STRUCTURAL_BONUS_MULT = 1.05    # if structural_flag = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISI Helper Functions\n",
    "\n",
    "def is_pitcher(position_value: str | float | None) -> bool:\n",
    "    \"\"\"\n",
    "    Detects Players with Pitcher as their Primary Position\n",
    "    Handles variations such as \"RP\", \"SP\", \"RHP\", \"LHP\", \"P\", and combined forms like \"RP/SP\", \"P/OF\", \"RHP-SP\".\n",
    "    \"\"\"\n",
    "    if position_value is None or (isinstance(position_value, float) and np.isnan(position_value)):\n",
    "        return False\n",
    "\n",
    "    s = str(position_value).strip().upper()\n",
    "    if s == \"\":\n",
    "        return False\n",
    "\n",
    "    # Delimiter split, remove whitespace\n",
    "    tokens = [t for t in re.split(r\"[/,;|\\-\\s]+\", s) if t]\n",
    "    return any(t in PITCHER_CODES for t in tokens)\n",
    "\n",
    "def denom_days(mode: str, lookback_years: int) -> float:\n",
    "    m = mode.lower().strip()\n",
    "    if m == 'games':\n",
    "        return 162.0 * lookback_years\n",
    "    if m == 'calendar':\n",
    "        return 365.0 * lookback_years\n",
    "    raise ValueError(\"Edit Configuration.  DENOM_MODE must be set to either 'calendar' or 'games'\")\n",
    "\n",
    "def load_term_map(term_map_path: str | Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the severity term map (.txt file)\n",
    "    Required cols: inj_norm_v6, anatomical_group, severity_tier, surgery_flag, structural_flag\n",
    "    \"\"\"\n",
    "    p = Path(term_map_path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"TERM_MAP_PATH not found: {p}\")\n",
    "\n",
    "    # file should be a txt, but if txt fails, csv can also be used (untested) \n",
    "    df = pd.read_csv(p, sep=\"\\t\", dtype=str, engine=\"python\")\n",
    "    if df.shape[1] == 1:\n",
    "        # csv fallback\n",
    "        df = pd.read_csv(p, dtype=str)\n",
    "\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # data integrity check\n",
    "    required = {\"inj_norm_v6\", \"anatomical_group\", \"severity_tier\", \"surgery_flag\", \"structural_flag\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f'Required cols missing: {sorted(missing)}')\n",
    "\n",
    "    df[\"inj_norm_v6\"] = df[\"inj_norm_v6\"].astype(str).str.strip()\n",
    "    df = df[df[\"inj_norm_v6\"].notna() & (df[\"inj_norm_v6\"] != \"\") & (df[\"inj_norm_v6\"] != \"0\")].copy()\n",
    "\n",
    "    df[\"anatomical_group\"] = df[\"anatomical_group\"].astype(str).str.strip()\n",
    "    df[\"severity_tier\"] = pd.to_numeric(df[\"severity_tier\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    df[\"surgery_flag\"] = pd.to_numeric(df[\"surgery_flag\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    df[\"structural_flag\"] = pd.to_numeric(df[\"structural_flag\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    df = df.drop_duplicates(subset=[\"inj_norm_v6\"], keep=\"first\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061aa1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create injury weights\n",
    "\n",
    "def build_bucket_weights() -> Tuple[Dict[str, float], Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Base anatomical-group risk weights\n",
    "    Apply severity multipliers separately\n",
    "    Default for unknown buckets = 1.00\n",
    "    Minimum for weights is set to 1.00.\n",
    "    \"\"\"\n",
    "    hitter_weights = {\n",
    "        # Throwing related injuries (TJ is more improtant for pitchers than position players)\n",
    "        \"Tommy John\": 1.20,\n",
    "        \"Elbow\": 1.10,\n",
    "        \"Flexor Tendon\": 1.15,\n",
    "        \"Shoulder\": 1.15,\n",
    "\n",
    "        # Soft tissue and spinal injuries\n",
    "        \"Lower back\": 1.10,\n",
    "        \"Spinal disc\": 1.20,\n",
    "        \"Groin\": 1.20,\n",
    "        \"Hip\": 1.10,\n",
    "        \"Pelvis\": 1.10,\n",
    "        \"Hernia\": 1.10,\n",
    "        \"Calf\": 1.15,\n",
    "        \"Hamstring\": 1.20,\n",
    "        \"Quad\": 1.10,\n",
    "\n",
    "        # Lower body injuries\n",
    "        \"Knee\": 1.10,\n",
    "        \"Ankle\": 1.05,\n",
    "        \"Foot\": 1.05,\n",
    "        \"Achilles\": 1.15,\n",
    "        \"Shin\": 1.00,\n",
    "        \"Leg\": 1.05,\n",
    "\n",
    "        # Upper extremity (non-throwing related injuries)\n",
    "        \"Wrist\": 1.00,\n",
    "        \"Hand\": 1.00,\n",
    "        \"Finger\": 1.00,\n",
    "        \"Forearm\": 1.05,\n",
    "        \"Arm\": 1.00,\n",
    "\n",
    "        # General injuries\n",
    "        \"Head\": 1.15,\n",
    "        \"Face\": 1.00,\n",
    "        \"Neck\": 1.05,\n",
    "        \"Chest\": 1.00,\n",
    "        \"Abdominal\": 1.00,\n",
    "        \"Rib\": 1.00,\n",
    "        \"Toe\": 1.00,\n",
    "        \"Neurological / Nerve\": 1.10,\n",
    "        \"Vascular / Cardiac\": 1.20,\n",
    "        \"Vascular cardiac related\": 1.20,\n",
    "\n",
    "        # Non-injury related and miscellaneous\n",
    "        \"Illness\": 1.00,                 \n",
    "        \"Medical (Non-injury)\": 1.00,    \n",
    "        \"Miscellaneous\": 1.00,\n",
    "    }\n",
    "\n",
    "    # increased weights for pitchers due to nature of position and responsibilities\n",
    "    pitcher_weights = dict(hitter_weights)\n",
    "    pitcher_weights.update({\n",
    "        \"Tommy John\": 1.50,\n",
    "        \"Elbow\": 1.30,\n",
    "        \"Flexor Tendon\": 1.35,\n",
    "        \"Shoulder\": 1.30,\n",
    "        \"Forearm\": 1.20,\n",
    "        \"Arm\": 1.10,\n",
    "    })\n",
    "    return hitter_weights, pitcher_weights\n",
    "\n",
    "\n",
    "def standardize_bucket_name(bucket: str | None) -> str | None:\n",
    "    \"\"\"\n",
    "    Ensures naming conventions that were skipped in Injury Naming files are properly cleaned\n",
    "    Precautionary measure, will not do anything if there are no changes to make.\n",
    "    Normalize labels from the term map, reduces mismatches to weight dict keys.\n",
    "    \"\"\"\n",
    "    if bucket is None or (isinstance(bucket, float) and np.isnan(bucket)):\n",
    "        return None\n",
    "\n",
    "    b = str(bucket).strip()\n",
    "    if b == \"\":\n",
    "        return None\n",
    "\n",
    "    # deals with whitespace and slash variants\n",
    "    b_norm = \" \".join(b.replace(\"\\\\\", \"/\").split())\n",
    "    b_low = b_norm.lower()\n",
    "\n",
    "    canon = {\n",
    "        # vascular/cardiac variants\n",
    "        \"vascular / cardiac\": \"Vascular / Cardiac\",\n",
    "        \"vascular/cardiac\": \"Vascular / Cardiac\",\n",
    "        \"vascular cardiac related\": \"Vascular / Cardiac\",\n",
    "\n",
    "        # final variant cleaning terms\n",
    "        \"lower back\": \"Lower back\",\n",
    "        \"spinal disc\": \"Spinal disc\",\n",
    "        \"neurological / nerve\": \"Neurological / Nerve\",\n",
    "        \"medical (non-injury)\": \"Medical (Non-injury)\",\n",
    "    }\n",
    "\n",
    "    if b_low in canon:\n",
    "        return canon[b_low]\n",
    "\n",
    "    return b_norm\n",
    "\n",
    "def get_bucket_weight(bucket: str | None, is_pitcher_flag: bool,\n",
    "                      hitter_w: Dict[str, float], pitcher_w: Dict[str, float]) -> float:\n",
    "    \"\"\"\n",
    "    Safely returns bucket weight, default = 1.00\n",
    "    Standardizes bucket name prior to lookup\n",
    "    \"\"\"\n",
    "    b = standardize_bucket_name(bucket)\n",
    "    # ensures no weights are assigned 0.00, which would skew analysis\n",
    "    if b is None:\n",
    "        return 1.00\n",
    "    weights = pitcher_w if is_pitcher_flag else hitter_w\n",
    "    return float(weights.get(b, 1.00))\n",
    "\n",
    "# applys a severity factor for each INDIVIDUAL injury stint\n",
    "def severity_multiplier(severity_tier: int | float | None,\n",
    "                        surgery_flag: int | float | None,\n",
    "                        structural_flag: int | float | None,\n",
    "                        tier_mult: Dict[int, float],\n",
    "                        surgery_mult: float,\n",
    "                        structural_mult: float) -> float:\n",
    "    \"\"\"\n",
    "    Computes a per-stint severity multiplier\n",
    "    tier_mult: {tier 0 : 1.00, tier 1 : 1.00, tier 2 : 1.15, tier 3 : 1.30}\n",
    "    surgery_mult applies if surgery_flag = 1\n",
    "    structural_mult applies if structural_flag = 1\n",
    "    \"\"\"\n",
    "    tier = int(severity_tier) if pd.notna(severity_tier) else 0\n",
    "    if tier not in tier_mult:\n",
    "        tier = 0\n",
    "\n",
    "    mult = float(tier_mult.get(tier, 1.00))\n",
    "\n",
    "    if int(surgery_flag) == 1:\n",
    "        mult *= float(surgery_mult)\n",
    "    if int(structural_flag) == 1:\n",
    "        mult *= float(structural_mult)\n",
    "\n",
    "    return mult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes ISI weights\n",
    "def compute_isi_features(\n",
    "    contracts: pd.DataFrame,\n",
    "    injuries: pd.DataFrame,\n",
    "    term_map: pd.DataFrame,\n",
    "    hitter_w: Dict[str, float],\n",
    "    pitcher_w: Dict[str, float],\n",
    "    lookback_years: int = 3,\n",
    "    lambda_recency: float = 0.7,\n",
    "    denom_mode: str = \"calendar\",\n",
    "    days_cap: int = 800,\n",
    "    injury_to_contract_offset: float = 0.5,\n",
    "    id_col: str = \"_cid\",\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    # copy to preserve data integrity if errors occur\n",
    "    dfc = contracts.copy()\n",
    "    dfc[\"key_mlbam\"] = pd.to_numeric(dfc.get(\"key_mlbam\"), errors=\"coerce\")\n",
    "    dfc[\"year\"] = pd.to_numeric(dfc.get(\"year\"), errors=\"coerce\")\n",
    "\n",
    "    # row PK\n",
    "    if id_col not in dfc.columns:\n",
    "        dfc[id_col] = np.arange(len(dfc), dtype=int)\n",
    "\n",
    "    dfc[\"_contract_row_id\"] = dfc[id_col].astype(int)\n",
    "\n",
    "    dfc[\"lb_start\"] = dfc[\"year\"] - lookback_years\n",
    "    dfc[\"lb_end\"] = dfc[\"year\"] - 1\n",
    "\n",
    "    # Injury csv file data preparation\n",
    "    dfi = injuries.copy()\n",
    "    dfi[\"mlbamid\"] = pd.to_numeric(dfi.get(\"mlbamid\"), errors=\"coerce\")\n",
    "    dfi[\"season\"] = pd.to_numeric(dfi.get(\"season\"), errors=\"coerce\")\n",
    "    dfi[\"days_to_return\"] = pd.to_numeric(dfi.get(\"days_to_return\"), errors=\"coerce\")\n",
    "\n",
    "    # data integrity checks\n",
    "    dfi[\"days_capped\"] = dfi[\"days_to_return\"].clip(lower=0, upper=days_cap)\n",
    "    dfi[\"inj_norm_v6\"] = dfi[\"inj_norm_v6\"].astype(str).str.strip()\n",
    "\n",
    "    tm = term_map.rename(columns={\"anatomical_group\": \"bucket\"}).copy()\n",
    "    tm[\"bucket\"] = tm[\"bucket\"].map(standardize_bucket_name)\n",
    "\n",
    "    dfi = dfi.merge(\n",
    "        tm[[\"inj_norm_v6\", \"bucket\", \"severity_tier\", \"surgery_flag\", \"structural_flag\"]],\n",
    "        on=\"inj_norm_v6\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    dfi[\"bucket\"] = dfi[\"bucket\"].map(standardize_bucket_name)\n",
    "\n",
    "    merged = dfc[[\"_contract_row_id\", \"key_mlbam\", \"year\", \"position\", \"lb_start\", \"lb_end\"]].merge(\n",
    "        dfi[[\"mlbamid\", \"season\", \"days_capped\", \"inj_norm_v6\", \"bucket\", \"severity_tier\", \"surgery_flag\", \"structural_flag\"]],\n",
    "        left_on=\"key_mlbam\",\n",
    "        right_on=\"mlbamid\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # Lookback period filter\n",
    "    in_window = (\n",
    "        merged[\"season\"].notna()\n",
    "        & merged[\"year\"].notna()\n",
    "        & (merged[\"season\"] >= merged[\"lb_start\"])\n",
    "        & (merged[\"season\"] <= merged[\"lb_end\"])\n",
    "    )\n",
    "    merged = merged.loc[in_window].copy()\n",
    "\n",
    "    merged[\"is_pitcher\"] = merged[\"position\"].map(is_pitcher)\n",
    "\n",
    "    # Assign bucket weights\n",
    "    # utilizes 'is_pitcher' bool flag\n",
    "    merged[\"base_risk_w\"] = merged.apply(\n",
    "        lambda r: get_bucket_weight(\n",
    "            bucket=r.get(\"bucket\"),\n",
    "            is_pitcher_flag=bool(r.get(\"is_pitcher\")),\n",
    "            hitter_w=hitter_w,\n",
    "            pitcher_w=pitcher_w,\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # apply severity multiplier\n",
    "    merged[\"severity_tier\"] = pd.to_numeric(merged[\"severity_tier\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    merged[\"surgery_flag\"] = pd.to_numeric(merged[\"surgery_flag\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    merged[\"structural_flag\"] = pd.to_numeric(merged[\"structural_flag\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    merged[\"severity_mult\"] = merged.apply(\n",
    "        lambda r: severity_multiplier(\n",
    "            r.get(\"severity_tier\"),\n",
    "            r.get(\"surgery_flag\"),\n",
    "            r.get(\"structural_flag\"),\n",
    "            tier_mult=SEVERITY_TIER_MULT,\n",
    "            surgery_mult=SURGERY_BONUS_MULT,\n",
    "            structural_mult=STRUCTURAL_BONUS_MULT,\n",
    "        ),\n",
    "        axis=1,\n",
    "    ).astype(float)\n",
    "\n",
    "    merged[\"risk_w\"] = merged[\"base_risk_w\"] * merged[\"severity_mult\"]\n",
    "\n",
    "    # recency decay (season-based)\n",
    "    # Explanation: If injury season is Y-1, time since injury is equivalent to 1 + offset\n",
    "    merged[\"t_years\"] = (merged[\"year\"] - merged[\"season\"]).astype(float) + float(injury_to_contract_offset)\n",
    "    merged[\"t_years\"] = merged[\"t_years\"].clip(lower=0)\n",
    "\n",
    "    merged[\"recency_mult\"] = np.exp(-lambda_recency * merged[\"t_years\"])\n",
    "\n",
    "    ##################################\n",
    "    ###### Per-stint components ######\n",
    "    ##################################\n",
    "\n",
    "    merged[\"weighted_days\"] = merged[\"risk_w\"] * merged[\"days_capped\"]\n",
    "    merged[\"decayed_days\"] = merged[\"recency_mult\"] * merged[\"days_capped\"]\n",
    "    merged[\"recency_weighted_days\"] = merged[\"days_capped\"] * merged[\"risk_w\"] * merged[\"recency_mult\"]\n",
    "\n",
    "    # Convenience flags\n",
    "    # if greater than 3 appears, an error occurred, range should be 0-3\n",
    "    merged[\"tier3plus_flag\"] = (merged[\"severity_tier\"] >= 3).astype(int)\n",
    "\n",
    "    arm_buckets = {\"Tommy John\", \"Elbow\", \"Shoulder\", \"Flexor Tendon\", \"Forearm\", \"Arm\"}\n",
    "    merged[\"_is_arm_bucket\"] = merged[\"bucket\"].isin(arm_buckets).astype(int)\n",
    "    merged[\"_arm_days\"] = merged[\"days_capped\"] * merged[\"_is_arm_bucket\"]\n",
    "\n",
    "\n",
    "    ##################################\n",
    "    ####### Contract Aggregate #######\n",
    "    ##################################\n",
    "\n",
    "    agg = merged.groupby(\"_contract_row_id\", as_index=False).agg(\n",
    "        isi_D_days=(\"days_capped\", \"sum\"),\n",
    "        isi_N_stints=(\"days_capped\", \"size\"),\n",
    "        isi_S_raw=(\"weighted_days\", \"sum\"),\n",
    "        isi_C_raw=(\"decayed_days\", \"sum\"),\n",
    "\n",
    "        recency_weighted_days=(\"recency_weighted_days\", \"sum\"),\n",
    "\n",
    "        any_surgery_flag=(\"surgery_flag\", \"max\"),\n",
    "        any_structural_flag=(\"structural_flag\", \"max\"),\n",
    "        any_tier3plus_flag=(\"tier3plus_flag\", \"max\"),\n",
    "        isi_unique_seasons_with_inj=(\"season\", pd.Series.nunique),\n",
    "\n",
    "        arm_days=(\"__arm_days_safe\", \"sum\") if False else (\"_arm_days\", \"sum\"),\n",
    "    )\n",
    "\n",
    "    out = dfc.merge(agg, on=\"_contract_row_id\", how=\"left\")\n",
    "    fill0 = [\n",
    "        \"isi_D_days\", \"isi_N_stints\", \"isi_S_raw\", \"isi_C_raw\",\n",
    "        \"recency_weighted_days\", \"any_surgery_flag\", \"any_structural_flag\",\n",
    "        \"any_tier3plus_flag\", \"isi_unique_seasons_with_inj\", \"arm_days\"\n",
    "    ]\n",
    "    for col in fill0:\n",
    "        if col in out.columns:\n",
    "            out[col] = out[col].fillna(0)\n",
    "\n",
    "    # coverage indicators\n",
    "    inj_season_min = int(pd.to_numeric(injuries[\"season\"], errors=\"coerce\").min())\n",
    "    inj_season_max = int(pd.to_numeric(injuries[\"season\"], errors=\"coerce\").max())\n",
    "\n",
    "    out[\"isi_window_seasons_avail\"] = (\n",
    "        (np.minimum(out[\"lb_end\"], inj_season_max) - np.maximum(out[\"lb_start\"], inj_season_min) + 1)\n",
    "        .clip(lower=0)\n",
    "    ).astype(\"Int64\")\n",
    "    out[\"isi_full_window_flag\"] = (out[\"isi_window_seasons_avail\"] == lookback_years)\n",
    "\n",
    "    ##################################\n",
    "    ####### Norm, Burden Score #######\n",
    "    ##################################\n",
    "\n",
    "    denom = denom_days(denom_mode, lookback_years)\n",
    "\n",
    "    # Normalize components\n",
    "    base_max_w = max(max(hitter_w.values()), max(pitcher_w.values())) if hitter_w and pitcher_w else 1.0\n",
    "    sev_max = max(SEVERITY_TIER_MULT.values()) * SURGERY_BONUS_MULT * STRUCTURAL_BONUS_MULT\n",
    "    max_w = base_max_w * sev_max\n",
    "\n",
    "    out[\"isi_D_star\"] = (out[\"isi_D_days\"] / denom).clip(0, 1)\n",
    "    out[\"isi_S_star\"] = (out[\"isi_S_raw\"] / (denom * max_w)).clip(0, 1)\n",
    "\n",
    "    # recurrence normalization\n",
    "    N_MAX = 10.0\n",
    "    out[\"isi_R_star\"] = (np.log1p(out[\"isi_N_stints\"]) / np.log1p(N_MAX)).clip(0, 1)\n",
    "    out[\"isi_C_star\"] = (out[\"isi_C_raw\"] / denom).clip(0, 1)\n",
    "\n",
    "    # IGNORE THIS FOR NOW, THIS WAS IN REFERENCE TO A PREVIOUS ATTEMPT, USED FOR DIAGNOSES\n",
    "    out[\"ISI_v1_1\"] = 0.25 * (out[\"isi_D_star\"] + out[\"isi_S_star\"] + out[\"isi_R_star\"] + out[\"isi_C_star\"])\n",
    "\n",
    "    out[\"durability_days_rate\"] = (out[\"isi_D_days\"] / denom).clip(lower=0)\n",
    "    out[\"recency_weighted_days_rate\"] = (out[\"recency_weighted_days\"] / (denom * max_w)).clip(lower=0)\n",
    "    out[\"injury_burden\"] = np.log1p(out[\"recency_weighted_days_rate\"])\n",
    "\n",
    "    out[\"arm_share_days\"] = np.where(out[\"isi_D_days\"] > 0, out[\"arm_days\"] / out[\"isi_D_days\"], 0.0)\n",
    "\n",
    "    # Data integrity\n",
    "    # If no window found, treat as missing ISI score\n",
    "    miss_mask = (out[\"isi_window_seasons_avail\"] == 0)\n",
    "    out.loc[miss_mask, [\"ISI_v1_1\", \"injury_burden\", \"recency_weighted_days_rate\"]] = np.nan\n",
    "\n",
    "    return out.drop(columns=[\"_contract_row_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adcdfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audit Pipeline\n",
    "\n",
    "def build_coverage_report(\n",
    "    contracts: pd.DataFrame,\n",
    "    injuries: pd.DataFrame,\n",
    "    term_map: pd.DataFrame,\n",
    "    *,\n",
    "    lookback_years: int | None = None,\n",
    "    contract_year_col: str = \"year\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Diagnostics table\n",
    "    \"\"\"\n",
    "    c = contracts.copy()\n",
    "    i = injuries.copy()\n",
    "    tm = term_map.copy()\n",
    "\n",
    "    # normalize required columns\n",
    "    c[\"key_mlbam\"] = pd.to_numeric(c.get(\"key_mlbam\"), errors=\"coerce\")\n",
    "    c[contract_year_col] = pd.to_numeric(c.get(contract_year_col), errors=\"coerce\")\n",
    "\n",
    "    i[\"mlbamid\"] = pd.to_numeric(i.get(\"mlbamid\"), errors=\"coerce\")\n",
    "    i[\"season\"] = pd.to_numeric(i.get(\"season\"), errors=\"coerce\")\n",
    "    i[\"inj_norm_v6\"] = i.get(\"inj_norm_v6\").astype(str).str.strip()\n",
    "\n",
    "    tm[\"inj_norm_v6\"] = tm.get(\"inj_norm_v6\").astype(str).str.strip()\n",
    "\n",
    "    # Counts to determine if required components are found\n",
    "    n_contracts = int(len(c))\n",
    "    n_contracts_with_mlbam = int(c[\"key_mlbam\"].notna().sum())\n",
    "\n",
    "    n_inj_rows = int(len(i))\n",
    "    n_inj_rows_with_mlbam = int(i[\"mlbamid\"].notna().sum())\n",
    "\n",
    "    # Coverage Map\n",
    "    unique_terms_in_inj = pd.Series(i[\"inj_norm_v6\"]).replace({\"nan\": np.nan}).dropna()\n",
    "    unique_terms_in_inj = unique_terms_in_inj[unique_terms_in_inj != \"\"].unique().tolist()\n",
    "\n",
    "    mapped_terms = set(pd.Series(tm[\"inj_norm_v6\"]).replace({\"nan\": np.nan}).dropna().tolist())\n",
    "\n",
    "    n_terms = int(len(unique_terms_in_inj))\n",
    "    n_terms_mapped = int(sum(t in mapped_terms for t in unique_terms_in_inj))\n",
    "\n",
    "    # Below answers the question: How many contracts have at least one injury row\n",
    "    contracts_with_any_injury = int(\n",
    "        c.loc[c[\"key_mlbam\"].notna(), \"key_mlbam\"]\n",
    "         .isin(set(i.loc[i[\"mlbamid\"].notna(), \"mlbamid\"]))\n",
    "         .sum()\n",
    "    )\n",
    "\n",
    "    # Below answers the question: How many contracts have at least 1 injury in lookback period\n",
    "    contracts_with_injury_in_window = np.nan\n",
    "    if lookback_years is not None:\n",
    "        ct = c.loc[c[\"key_mlbam\"].notna() & c[contract_year_col].notna(),\n",
    "                   [\"key_mlbam\", contract_year_col]].copy()\n",
    "        ct[\"_rid\"] = np.arange(len(ct), dtype=int)\n",
    "        ct[\"lb_start\"] = ct[contract_year_col] - int(lookback_years)\n",
    "        ct[\"lb_end\"] = ct[contract_year_col] - 1\n",
    "\n",
    "        m = ct.merge(\n",
    "            i.loc[i[\"mlbamid\"].notna() & i[\"season\"].notna(), [\"mlbamid\", \"season\"]],\n",
    "            left_on=\"key_mlbam\",\n",
    "            right_on=\"mlbamid\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        in_window = (\n",
    "            m[\"season\"].notna()\n",
    "            & (m[\"season\"] >= m[\"lb_start\"])\n",
    "            & (m[\"season\"] <= m[\"lb_end\"])\n",
    "        )\n",
    "        contracts_with_injury_in_window = int(m.loc[in_window, \"_rid\"].nunique())\n",
    "\n",
    "    report = pd.DataFrame([{\n",
    "        \"contracts_rows\": n_contracts,\n",
    "        \"contracts_with_key_mlbam\": n_contracts_with_mlbam,\n",
    "        \"contracts_with_key_mlbam_pct\": (n_contracts_with_mlbam / n_contracts) if n_contracts else np.nan,\n",
    "\n",
    "        \"injury_rows\": n_inj_rows,\n",
    "        \"injury_rows_with_mlbamid\": n_inj_rows_with_mlbam,\n",
    "        \"injury_rows_with_mlbamid_pct\": (n_inj_rows_with_mlbam / n_inj_rows) if n_inj_rows else np.nan,\n",
    "\n",
    "        \"contracts_with_any_injury_match_on_mlbam\": contracts_with_any_injury,\n",
    "        \"contracts_with_any_injury_match_on_mlbam_pct\":\n",
    "            (contracts_with_any_injury / n_contracts_with_mlbam) if n_contracts_with_mlbam else np.nan,\n",
    "\n",
    "        \"unique_injury_terms_in_injuries\": n_terms,\n",
    "        \"unique_injury_terms_mapped_in_term_map\": n_terms_mapped,\n",
    "        \"unique_injury_terms_mapped_pct\": (n_terms_mapped / n_terms) if n_terms else np.nan,\n",
    "\n",
    "        \"lookback_years_for_window_check\": lookback_years,\n",
    "        \"contracts_with_injury_in_lookback_window\": contracts_with_injury_in_window,\n",
    "    }])\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "def build_audit_table(\n",
    "    term_map: pd.DataFrame,\n",
    "    hitter_w: Dict[str, float],\n",
    "    pitcher_w: Dict[str, float],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Term-level audit\n",
    "    Documents how each injury term affects\n",
    "    to ISI\n",
    "    Measurements for: anatomical bucket, severity tier, and effective weights\n",
    "    \"\"\"\n",
    "    tm = term_map.copy()\n",
    "    tm = tm.rename(columns={\"anatomical_group\": \"bucket\"})\n",
    "    tm[\"bucket\"] = tm[\"bucket\"].map(standardize_bucket_name)\n",
    "\n",
    "    tm[\"severity_tier\"] = pd.to_numeric(tm[\"severity_tier\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    tm[\"surgery_flag\"] = pd.to_numeric(tm[\"surgery_flag\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    tm[\"structural_flag\"] = pd.to_numeric(tm[\"structural_flag\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    # Severity mult\n",
    "    tm[\"tier_mult\"] = tm[\"severity_tier\"].map(\n",
    "        lambda x: SEVERITY_TIER_MULT.get(int(x), 1.00)\n",
    "    ).astype(float)\n",
    "\n",
    "    tm[\"surgery_mult\"] = np.where(tm[\"surgery_flag\"] == 1, SURGERY_BONUS_MULT, 1.00)\n",
    "    tm[\"structural_mult\"] = np.where(tm[\"structural_flag\"] == 1, STRUCTURAL_BONUS_MULT, 1.00)\n",
    "\n",
    "    tm[\"severity_mult\"] = tm[\"tier_mult\"] * tm[\"surgery_mult\"] * tm[\"structural_mult\"]\n",
    "\n",
    "    # Base bucket weights\n",
    "    def w_hitter(bucket: str | None) -> float:\n",
    "        if bucket is None or pd.isna(bucket) or str(bucket).strip() == \"\":\n",
    "            return 1.00\n",
    "        return float(hitter_w.get(bucket, 1.00))\n",
    "\n",
    "    def w_pitcher(bucket: str | None) -> float:\n",
    "        if bucket is None or pd.isna(bucket) or str(bucket).strip() == \"\":\n",
    "            return 1.00\n",
    "        return float(pitcher_w.get(bucket, 1.00))\n",
    "\n",
    "    tm[\"weight_hitter_base\"] = tm[\"bucket\"].map(w_hitter)\n",
    "    tm[\"weight_pitcher_base\"] = tm[\"bucket\"].map(w_pitcher)\n",
    "\n",
    "    tm[\"weight_hitter_effective\"] = tm[\"weight_hitter_base\"] * tm[\"severity_mult\"]\n",
    "    tm[\"weight_pitcher_effective\"] = tm[\"weight_pitcher_base\"] * tm[\"severity_mult\"]\n",
    "\n",
    "    # Final column ordering\n",
    "    cols = [\n",
    "        \"inj_norm_v6\",\n",
    "        \"bucket\",\n",
    "        \"severity_tier\",\n",
    "        \"surgery_flag\",\n",
    "        \"structural_flag\",\n",
    "        \"tier_mult\",\n",
    "        \"surgery_mult\",\n",
    "        \"structural_mult\",\n",
    "        \"severity_mult\",\n",
    "        \"weight_hitter_base\",\n",
    "        \"weight_pitcher_base\",\n",
    "        \"weight_hitter_effective\",\n",
    "        \"weight_pitcher_effective\",\n",
    "    ]\n",
    "\n",
    "    tm = tm[cols].sort_values(\n",
    "        [\"bucket\", \"severity_tier\", \"inj_norm_v6\"],\n",
    "        kind=\"stable\"\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return tm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f9063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrote sweep-wide: C:\\Users\\brend\\Desktop\\SABR_research_proposal\\injuries\\ISI Computations\\ISI_update\\contracts_with_isi_v2_SWEEP_WIDE.csv\n",
      "Wrote sweep-summary: C:\\Users\\brend\\Desktop\\SABR_research_proposal\\injuries\\ISI Computations\\ISI_update\\contracts_with_isi_v2_SWEEP_SUMMARY.csv\n",
      "\n",
      "Sweep summary:\n",
      "       setting  injury_burden_nonnull_pct  injury_burden_mean  \\\n",
      "0  lb3_lam0p35                   0.845622            0.018077   \n",
      "1   lb3_lam0p5                   0.845622            0.013315   \n",
      "2   lb3_lam0p7                   0.845622            0.008972   \n",
      "3  lb5_lam0p35                   0.845622            0.011712   \n",
      "4   lb5_lam0p5                   0.845622            0.008439   \n",
      "5   lb5_lam0p7                   0.845622            0.005574   \n",
      "\n",
      "   injury_burden_p90  injury_burden_p99  rwd_rate_mean  durability_rate_mean  \\\n",
      "0           0.040412           0.229917       0.019190              0.051868   \n",
      "1           0.029746           0.175212       0.013930              0.051868   \n",
      "2           0.020440           0.111603       0.009263              0.051868   \n",
      "3           0.026356           0.144185       0.012155              0.035318   \n",
      "4           0.019027           0.108777       0.008676              0.035318   \n",
      "5           0.012958           0.068848       0.005684              0.035318   \n",
      "\n",
      "   any_surgery_rate  any_tier3plus_rate  corr_injury_burden_vs_guarantee  \n",
      "0          0.117512            0.117512                        -0.045501  \n",
      "1          0.117512            0.117512                        -0.046969  \n",
      "2          0.117512            0.117512                        -0.047939  \n",
      "3          0.127880            0.127880                        -0.046892  \n",
      "4          0.127880            0.127880                        -0.047951  \n",
      "5          0.127880            0.127880                        -0.048466  \n"
     ]
    }
   ],
   "source": [
    "# This blocks applies the above functions\n",
    "\n",
    "def main() -> None:\n",
    "    # load input\n",
    "    contracts = pd.read_csv(CONTRACTS_CSV)\n",
    "\n",
    "    # restrict to contracts whose first season is within the injury file\n",
    "    contracts[\"term_start_year\"] = pd.to_numeric(contracts[\"term_start_year\"], errors=\"coerce\")\n",
    "    contracts = contracts.dropna(subset=[\"term_start_year\"]).copy()\n",
    "    contracts = contracts[(contracts[\"term_start_year\"] >= 2020) & (contracts[\"term_start_year\"] <= 2025)].copy()\n",
    "\n",
    "    # Data Integrity\n",
    "    # Ensures ISI anchor year matches contract start year\n",
    "    contracts[\"year\"] = contracts[\"term_start_year\"]\n",
    "\n",
    "    injuries = pd.read_csv(INJURIES_CSV)\n",
    "    term_map = load_term_map(TERM_MAP_PATH)\n",
    "\n",
    "    # Build baseline weights\n",
    "    hitter_w, pitcher_w = build_bucket_weights()\n",
    "\n",
    "    # ensure proper naming conventions\n",
    "    def suffix_df(df: pd.DataFrame, suffix: str, keep_cols: list[str]) -> pd.DataFrame:\n",
    "        out = df.copy()\n",
    "        rename = {c: f\"{c}__{suffix}\" for c in out.columns if c not in keep_cols}\n",
    "        return out.rename(columns=rename)\n",
    "\n",
    "    def summarize_setting(df: pd.DataFrame, suffix: str) -> dict:\n",
    "        \"\"\"\n",
    "        Diagnostics prior to any training\n",
    "        \"\"\"\n",
    "        cols = {\n",
    "            \"injury_burden\": f\"injury_burden__{suffix}\",\n",
    "            \"rwd_rate\": f\"recency_weighted_days_rate__{suffix}\",\n",
    "            \"dur_rate\": f\"durability_days_rate__{suffix}\",\n",
    "            \"any_surg\": f\"any_surgery_flag__{suffix}\",\n",
    "            \"tier3\": f\"any_tier3plus_flag__{suffix}\",\n",
    "        }\n",
    "\n",
    "        s = {}\n",
    "        s[\"setting\"] = suffix\n",
    "\n",
    "        ib = df.get(cols[\"injury_burden\"])\n",
    "        if ib is not None:\n",
    "            s[\"injury_burden_nonnull_pct\"] = float(ib.notna().mean())\n",
    "            s[\"injury_burden_mean\"] = float(ib.dropna().mean()) if ib.notna().any() else np.nan\n",
    "            s[\"injury_burden_p90\"] = float(ib.dropna().quantile(0.90)) if ib.notna().any() else np.nan\n",
    "            s[\"injury_burden_p99\"] = float(ib.dropna().quantile(0.99)) if ib.notna().any() else np.nan\n",
    "\n",
    "        rwd = df.get(cols[\"rwd_rate\"])\n",
    "        if rwd is not None:\n",
    "            s[\"rwd_rate_mean\"] = float(rwd.dropna().mean()) if rwd.notna().any() else np.nan\n",
    "\n",
    "        dur = df.get(cols[\"dur_rate\"])\n",
    "        if dur is not None:\n",
    "            s[\"durability_rate_mean\"] = float(dur.dropna().mean()) if dur.notna().any() else np.nan\n",
    "\n",
    "        surg = df.get(cols[\"any_surg\"])\n",
    "        if surg is not None:\n",
    "            s[\"any_surgery_rate\"] = float((surg.fillna(0) > 0).mean())\n",
    "\n",
    "        tier3 = df.get(cols[\"tier3\"])\n",
    "        if tier3 is not None:\n",
    "            s[\"any_tier3plus_rate\"] = float((tier3.fillna(0) > 0).mean())\n",
    "\n",
    "        # Data Integrity\n",
    "        if \"guarantee_total_real_2025\" in df.columns and ib is not None:\n",
    "            y = pd.to_numeric(df[\"guarantee_total_real_2025\"], errors=\"coerce\")\n",
    "            x = pd.to_numeric(ib, errors=\"coerce\")\n",
    "            ok = y.notna() & x.notna()\n",
    "            s[\"corr_injury_burden_vs_guarantee\"] = float(x[ok].corr(y[ok])) if ok.sum() >= 30 else np.nan\n",
    "\n",
    "        return s\n",
    "\n",
    "    # PK\n",
    "    contracts = contracts.copy()\n",
    "    contracts[\"_cid\"] = np.arange(len(contracts), dtype=int)\n",
    "\n",
    "    PARAM_GRID = [\n",
    "        {\"lookback_years\": 3, \"lambda_recency\": 0.35},\n",
    "        {\"lookback_years\": 3, \"lambda_recency\": 0.50},\n",
    "        {\"lookback_years\": 3, \"lambda_recency\": 0.70},\n",
    "        {\"lookback_years\": 5, \"lambda_recency\": 0.35},\n",
    "        {\"lookback_years\": 5, \"lambda_recency\": 0.50},\n",
    "        {\"lookback_years\": 5, \"lambda_recency\": 0.70},\n",
    "    ]\n",
    "\n",
    "    # Cols to keep\n",
    "    BASE_KEEP = [\n",
    "        \"_cid\",\n",
    "        \"player_name\", \"key_mlbam\", \"year\", \"position\",\n",
    "        \"guarantee_total_real_2025\",\n",
    "        \"term_start_year\", \"term_years\",\n",
    "    ]\n",
    "\n",
    "    BASE_KEEP = [c for c in BASE_KEEP if c in contracts.columns]\n",
    "\n",
    "    wide = contracts[BASE_KEEP].copy()\n",
    "    summary_rows = []\n",
    "\n",
    "    for p in PARAM_GRID:\n",
    "        lb = int(p[\"lookback_years\"])\n",
    "        lam = float(p[\"lambda_recency\"])\n",
    "        suffix = f\"lb{lb}_lam{str(lam).replace('.', 'p')}\"\n",
    "\n",
    "        out = compute_isi_features(\n",
    "            contracts=contracts,\n",
    "            injuries=injuries,\n",
    "            term_map=term_map,\n",
    "            hitter_w=hitter_w,\n",
    "            pitcher_w=pitcher_w,\n",
    "            lookback_years=lb,\n",
    "            lambda_recency=lam,\n",
    "            denom_mode=DENOM_MODE,\n",
    "            days_cap=DAYS_CAP,\n",
    "            injury_to_contract_offset=INJURY_TO_CONTRACT_OFFSET,\n",
    "            id_col=\"_cid\",\n",
    "        )\n",
    "\n",
    "        isi_cols = [\n",
    "            \"_cid\",\n",
    "            \"ISI_v1_1\",\n",
    "            \"isi_D_days\", \"isi_N_stints\",\n",
    "            \"recency_weighted_days\", \"recency_weighted_days_rate\",\n",
    "            \"durability_days_rate\", \"injury_burden\",\n",
    "            \"any_surgery_flag\", \"any_structural_flag\", \"any_tier3plus_flag\",\n",
    "            \"arm_days\", \"arm_share_days\",\n",
    "            \"isi_window_seasons_avail\", \"isi_full_window_flag\",\n",
    "        ]\n",
    "        isi_cols = [c for c in isi_cols if c in out.columns]\n",
    "\n",
    "        out_small = out[isi_cols].copy()\n",
    "        out_small = suffix_df(out_small, suffix=suffix, keep_cols=[\"_cid\"])\n",
    "\n",
    "        wide = wide.merge(out_small, on=\"_cid\", how=\"left\")\n",
    "\n",
    "        summary_rows.append(summarize_setting(wide, suffix=suffix))\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "    # sweep outputs\n",
    "    wide.to_csv(OUT_CONTRACTS.replace(\".csv\", \"_SWEEP_WIDE.csv\"), index=False)\n",
    "    summary_df.to_csv(OUT_CONTRACTS.replace(\".csv\", \"_SWEEP_SUMMARY.csv\"), index=False)\n",
    "\n",
    "    print(\"\\nWrote sweep-wide:\", OUT_CONTRACTS.replace(\".csv\", \"_SWEEP_WIDE.csv\"))\n",
    "    print(\"Wrote sweep-summary:\", OUT_CONTRACTS.replace(\".csv\", \"_SWEEP_SUMMARY.csv\"))\n",
    "    print(\"\\nSweep summary:\")\n",
    "    print(summary_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d1aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage report\n",
    "    coverage = build_coverage_report(contracts, injuries, term_map)\n",
    "    coverage.to_csv(OUT_COVERAGE, index=False)\n",
    "\n",
    "    # Compute ISI (severity-enabled, updated)\n",
    "    out = compute_isi_features(\n",
    "        contracts=contracts,\n",
    "        injuries=injuries,\n",
    "        term_map=term_map,\n",
    "        hitter_w=hitter_w,\n",
    "        pitcher_w=pitcher_w,\n",
    "        lookback_years=LOOKBACK_YEARS,\n",
    "        lambda_recency=RECENCY_LAMBDA,\n",
    "        denom_mode=DENOM_MODE,\n",
    "        days_cap=DAYS_CAP,\n",
    "        injury_to_contract_offset=INJURY_TO_CONTRACT_OFFSET,\n",
    "    )\n",
    "\n",
    "    # Export main output + audit table\n",
    "    out.to_csv(OUT_CONTRACTS, index=False)\n",
    "    audit = build_audit_table(term_map, hitter_w, pitcher_w)\n",
    "    audit.to_csv(OUT_AUDIT_TABLE, index=False)\n",
    "\n",
    "    print(\"\\nWrote:\", OUT_CONTRACTS)\n",
    "    print(\"Wrote:\", OUT_AUDIT_TABLE)\n",
    "    print(\"Wrote:\", OUT_COVERAGE)\n",
    "\n",
    "    # top 15 by injury burden, allows to quickly find injuries\n",
    "    cols_show = [\n",
    "        \"player_name\", \"year\", \"position\",\n",
    "        \"guarantee_total_real_2025\",\n",
    "        \"injury_burden\",\n",
    "        \"recency_weighted_days\", \"recency_weighted_days_rate\",\n",
    "        \"durability_days_rate\", \"isi_D_days\", \"isi_N_stints\",\n",
    "        \"any_surgery_flag\", \"any_tier3plus_flag\", \"arm_share_days\",\n",
    "        \"isi_window_seasons_avail\", \"isi_full_window_flag\",\n",
    "    ]\n",
    "    cols_show = [c for c in cols_show if c in out.columns]\n",
    "    top = out.dropna(subset=[\"injury_burden\"]).sort_values(\"injury_burden\", ascending=False).head(15)\n",
    "    print(\"\\nTop 15 injury burden contracts:\")\n",
    "    print(top[cols_show].to_string(index=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sabr_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
